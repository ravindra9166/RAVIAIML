# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K0l2H5riClJV1KU_atTXkFgzediqihyW
"""

# Importing necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Load the wine quality dataset from a CSV file (you can upload the wine dataset in Colab)
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'
data = pd.read_csv(url, delimiter=';')

# Displaying the first few rows of the dataset
print("First few rows of the dataset:")
print(data.head())

# Splitting the data into features (X) and target (y)
X = data.drop(columns=['quality'])
y = data['quality']

# Splitting the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Linear Regression Model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
y_pred_lr = lr_model.predict(X_test)

# Random Forest Model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

# Calculating the accuracy for Linear Regression using R-squared and RMSE
r2_lr = r2_score(y_test, y_pred_lr)
rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))

# Calculating the accuracy for Random Forest using R-squared and RMSE
r2_rf = r2_score(y_test, y_pred_rf)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))

# Displaying the results
print("\nModel Performance:")
print("Linear Regression:")
print(f"R-squared: {r2_lr}")
print(f"RMSE: {rmse_lr}")

print("\nRandom Forest:")
print(f"R-squared: {r2_rf}")
print(f"RMSE: {rmse_rf}")

# Plotting the comparison of model predictions vs actual values
plt.figure(figsize=(12, 6))

# Plot Linear Regression predictions
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred_lr, color='blue', label="Linear Regression")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2)
plt.title('Linear Regression: Actual vs Predicted')
plt.xlabel('Actual Quality')
plt.ylabel('Predicted Quality')

# Plot Random Forest predictions
plt.subplot(1, 2, 2)
plt.scatter(y_test, y_pred_rf, color='green', label="Random Forest")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2)
plt.title('Random Forest: Actual vs Predicted')
plt.xlabel('Actual Quality')
plt.ylabel('Predicted Quality')

plt.tight_layout()
plt.show()

# Bar Graph Comparison
models = ['Linear Regression', 'Random Forest']
r2_scores = [r2_lr, r2_rf]
rmse_scores = [rmse_lr, rmse_rf]

plt.figure(figsize=(8, 5))
bar_width = 0.4
index = np.arange(len(models))

plt.bar(index, r2_scores, bar_width, label='R-squared', color='skyblue')
plt.bar(index + bar_width, rmse_scores, bar_width, label='RMSE', color='salmon')

plt.xlabel('Models')
plt.title('Model Comparison: R-squared vs RMSE')
plt.xticks(index + bar_width / 2, models)
plt.legend()
plt.tight_layout()
plt.show()

# Taking user input for wine quality prediction
print("\n--- Predict Wine Quality ---")
input_data = []
attributes = [
    "fixed acidity", "volatile acidity", "citric acid", "residual sugar", "chlorides",
    "free sulfur dioxide", "total sulfur dioxide", "density", "pH", "sulphates", "alcohol"
]

print("Please provide the following inputs:")

for attribute in attributes:
    value = float(input(f"Enter value for {attribute}: "))
    input_data.append(value)

# Reshaping input_data for prediction
input_data = np.array(input_data).reshape(1, -1)

# Predicting wine quality using both models
pred_lr = lr_model.predict(input_data)
pred_rf = rf_model.predict(input_data)

# Displaying predictions
print("\nPredicted Wine Quality (Linear Regression):", pred_lr[0])
print("Predicted Wine Quality (Random Forest):", pred_rf[0])

# Calculating the average of both predictions
avg_pred = (pred_lr[0] + pred_rf[0]) / 2
print(f"Average Prediction: {avg_pred:.2f}")

# Displaying the better model based on accuracy (R-squared)
if r2_lr > r2_rf:
    print("Best model: Linear Regression")
else:
    print("Best model: Random Forest")